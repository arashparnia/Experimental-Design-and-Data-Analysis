---
title: "Assignment 2, EDDA 2017"
author: "Fabio Curi Paixao (2592802) Arash Parnia (2591051) - Group 22"
date: "19 April 2017"
output:
  pdf_document: default
  html_notebook: default
---



## Introduction

In the present document, the results for the second and third assignment of the EDDA course are presented.

## Assignment 2

### Exercise 1

#### 1

The following R code will check whether the 'telephone.txt' dataset stems from the exponential distribution exp(0.035).

```{r}
telephone = read.table('telephone.txt')
d <- as.numeric(levels(telephone$V1))[telephone$V1]
d <- d[!is.na(d)] 

B=1000
Tstar=numeric(B)
tall = numeric(B)
for(i in 1:B){
  Xstar=sample(d,replace=TRUE)
  Tstar[i]=median(Xstar)
  tall[i] = median(rexp(n = B, rate = 0.035))
}

# Tstar25=quantile(Tstar,0.025)
# Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
# T1 = mean(d)
# c(2*T1-Tstar975,2*T1-Tstar25)


t = median(tall)

pl=sum(Tstar<t)/B
pr=sum(Tstar>t)/B
p=2*min(pl,pr)
p

```
Since the p-value in lower than 0.05, we reject H0 and we conclude that it is not likely that the sample comes from the standard exponential distribution exp(0.035).

#### 2 

```{r}
hist(d,prob=TRUE)
```
An appropriate plot for this data is the histogram shown here above, as it indicates the amplitudes in which the clients lie with their first month bills. 
As the histogram indicates, the highest portion of the sample lies in lower intervals. However, a considerable portion of the same sample lies in the end of the histogram, which indicates that their bills have been rather expensive. Thus, as consultant, we could advise this company to propose to their clients a new offer in which their bills would have a fixed price, however with limited amount of calls. Thus, we could expect the beginning of the histogram to remain the same, an averaging in the middle, and a shortening in the end. 

### Exercise 2 

First of all, we will make the adjusments necessary for the three databases to be able to be compared. These adjustments are needed since the measurement procedures between both scientists were different.

```{r}
light1879 = scan(file="light1879.txt");
light1882 = scan(file="light1882.txt");
light = scan(file="light.txt");

light = light/1000  + 24.8

light = 7.442 * 1000 /light 
light = light * 1000


light1879 = light1879 + 299000
light1882 = light1882 + 299000

light = light[light > 0]
```

#### 1

Here below are the histograms and the boxplots for the three datasets.

```{r}
par(mfrow=c(1,3))
hist(light1879,prob = T)
hist(light1882,prob = T)
hist(light,prob = T)

par(mfrow=c(1,3))
boxplot(light1879)
boxplot(light1882)
boxplot(light)
```
As it can be seen from the boxplots, there is a significant difference between the measurements made in 1879 by Michelson in 1879 and 1882 and from Newcomb's measurements from 1882. The median values of the boxplots are considerably different between the former and these two last. Furthermore, between the two measurements from 1882, Newcomb managed to obtain his results in a fairly narrower amplitude, which is maybe thanks to his methodology and/or equipments used.

#### 2

Here, we will make use of both mean and median values of each dataset. We have created a function to take into account this choice. The results are given right after.

```{r}
# for means

B=1000
T1 = mean(light1879)
d = light1879
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=mean(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = mean(d)
c(2*T1-Tstar975,2*T1-Tstar25)

mean(light1882)
B=1000
T1 = mean(light1882)
d = light1882
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=mean(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = mean(d)
c(2*T1-Tstar975,2*T1-Tstar25)

mean(light)
B=1000
T1 = mean(light)
d = light
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=mean(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = mean(d)
c(2*T1-Tstar975,2*T1-Tstar25)

# for median 

median(light1879)
B=1000
T1 = median(light1879)
d = light1879
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=median(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = median(d)
c(2*T1-Tstar975,2*T1-Tstar25)

median(light1882)
B=1000
T1 = median(light1882)
d = light1882
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=median(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = median(d)
c(2*T1-Tstar975,2*T1-Tstar25)

median(light)
B=1000
T1 = median(light)
d = light
Tstar=numeric(B)
for(i in 1:B){
Xstar=sample(d,replace=TRUE)
Tstar[i]=median(Xstar)
}

Tstar25=quantile(Tstar,0.025)
Tstar975=quantile(Tstar,0.975)
# sum(Tstar<Tstar25)
T1 = median(d)
c(2*T1-Tstar975,2*T1-Tstar25)
```

#### 3

Intervals show that all measurements are closely ranged around 299000.

#### 4 

Speed of light is 299792458 m / s and 299792.458 kps, and it closely ressembles the measurements of the French physicists Fizeau and Foucault.


### Exercise 3

#### 1

Now, we will explore the file "klm.txt". We will now test the null hypothesis that the median duration is smaller or equal to 32 days against the alternative hypothesis that this median is greater than 32 days.

```{r}
klm = read.table('klm.txt')
klm = c(klm$V1,klm$V2,klm$V3,klm$V4,klm$V5)
par(mfrow=c(1,2))
hist(klm)
boxplot(klm)
summary(klm)
library(BSDA)
SIGN.test(klm , md = 32,alternative = "greater")
```

The sign test concludes that the true median is not equal to 32, therefore inducing to reject the null hypothesis that the median is smaller or equal to 32 days.

#### 2

```{r}
klm-70
rank(abs(klm-70))
rank(abs(klm-70))[klm-70>0]
sum(rank(abs(klm-70))[klm-70>0])

wilcox.test(klm,mu=70,alternative = "less")
```
The Wilcox test shows that the null hypothesis indicating that the delivery period is maximum of 70 days can not be rejected. Therefore it is plausible to think that parts arrive after the maximum.


### Exercise 4

In this subsection, we will explore the file "clouds.txt".

```{r}
clouds = read.table('clouds.txt',header = FALSE)
a=as.numeric(levels(clouds$V1))[clouds$V1]
a=a[2:end(a)]
b=as.numeric(levels(clouds$V2))[clouds$V2]
b=b[2:end(b)]
```

#### 1 

To see if there was an improvement, deterioration, or if the means of times have remained substantially the same (hypothesis H0), we need to make a Student's t-test for paired samples:
```{r}
t.test(a,b, paired=TRUE)
```
Here, we asked R to check whether the mean of the values contained in the vector a is equal to the mean of the values contained in the vector b, thus checking whether there has not been any improvement/nor worsening in the amount of rainfall after seeding (H0).
The p-value is right below 0.05, so we reject the null hypothesis.

Then, we perform Mann-Whitney test and the Kolmogorov-Smirnov test.

```{r}
wilcox.test(a,b,paired=TRUE) 
```
The null hypothesis is that the rainfall of the two sample unseeded and seeded clouds are identical populations. As the p-value turns out to be 0.006131, and is less than the .05 significance level, we again reject the null hypothesis.

```{r}
ks.test(a,b,paired=TRUE)
```

Here, the same conclusion can be made, as the p-value for is below 0.05. In the present case, applying these three tests might not be applicable, as it could be proved in practice that seeding clouds would be an improvement for the amount of rainfall. What is lacking here is maybe the inclusion of other variables important for such rise of rainfall, such as local temperature, wind, among others. Or simply, make use of other procedures to calculate an eventual evidence.

#### 2

Now, we will take the squared root of the values in the file.

```{r}
a_2=sqrt(a)
b_2=sqrt(b)
```

```{r}
t.test(a_2,b_2, paired=TRUE)
wilcox.test(a_2,b_2,paired=TRUE) 
ks.test(a_2,b_2,paired=TRUE)
```

The values for the t.test dropped from 0.04407 to 0.01278; for the Wilcoxon, it increased from 0.006131 to 0.009383, and for the Kolmogorov-Smirnov, it remained the same.

#### 3

Finally, the squared root of the squared root of the values in the file are considered.

```{r}
a_3=sqrt(a_2)
b_3=sqrt(b_2)
```

```{r}
t.test(a_3,b_3, paired=TRUE)
wilcox.test(a_3,b_3,paired=TRUE) 
ks.test(a_3,b_3,paired=TRUE)
```

Now, the values for the t.test dropped from 0.01278 to 0.008811; for the Wilcoxon, it decreased from 0.009383 to 0.007291, and for the Kolmogorov-Smirnov, it still remained the same.

## Assignment 3

### Exercise 1

#### 1

In this subsection, we will explore the file "peruvians.txt" with the data of Peruvian men after migrating to a modern society.

```{r}
peruvians = read.table('peruvians.txt')
peruvians = peruvians[,-c(5,6,7)]
pairs(peruvians)
```

We obtain the pairs plot for the correlation between variables age (V1), weight (V3), length (V4), wrist (V8), systolic (V9) and diastolic (V10) with migration (V2). The area of interest is concentrated on the second row, and also second column. From this plot, we decided that only the variable "age" would be correlated to "migration", as it is the only which seemly respects an uprising behaviour, as in the oldest the person is, the longest he/she would be expected to having been under the status of migrant. 

#### 2

Now, we will study the correlation of these variables with "migration".

```{r}
age=as.numeric(levels(peruvians$V1))[peruvians$V1]
age=age[2:end(age)]
migration=as.numeric(levels(peruvians$V2))[peruvians$V2]
migration=migration[2:end(migration)]
weight=as.numeric(levels(peruvians$V3))[peruvians$V3]
weight=weight[2:end(weight)]
length=as.numeric(levels(peruvians$V4))[peruvians$V4]
length=length[2:end(length)]
wrist=as.numeric(levels(peruvians$V8))[peruvians$V8]
wrist=wrist[2:end(wrist)]
systolic=as.numeric(levels(peruvians$V9))[peruvians$V9]
systolic=systolic[2:end(systolic)]
diastolic=as.numeric(levels(peruvians$V10))[peruvians$V10]
diastolic=diastolic[2:end(diastolic)]
```
```{r}
cor(age,migration)
cor(weight,migration)
cor(length,migration)
cor(wrist,migration)
cor(systolic,migration)
cor(diastolic,migration)
```

By the numbers here above, we can confirm what was before stated that the variable which is most likely to be correlated to migration is age. The other variables had a very low or even negative values. The variable "weight" had correlation of 0.4811, which is not as low as the others, however we can't consider here it being correlated to "migration" as this value is still low.

### Exercise 2

The best way to represent this data is through separating it into two different datasets: one for "lemo" and another for "energy".

```{r}
run = read.table('run.txt')
lemo = subset(run,drink=="lemo")[,-c(3)]
energy = subset(run,drink=="energy")[,-c(3)]
```

#### 1

A graphical representation of the data is here shown:

```{r}
boxplot(run[,-c(3)])

par(mfrow=c(1,1))
boxplot(lemo)
boxplot(energy)
```

In general, the median of the boxplot after having drunk the lemon soda was higher, while for the energy drink it was lower. However, the upper and lower limits are limited in a wider range for both cases after having drunk the beverages.

#### 2

```{r}
t.test(lemo$before, lemo$after);

t.test(energy$before, energy$after);
```
The results of the t.test show that, for those having drunk "lemo", the hypothesis H0 which states that the mean values before and after drinking the beverage are equal, is maintained as the p-value of 0.6203 is clearly higher than 0.05.
For the beverage "energy", the p-value of 0.3407 maintains the hypothesis H0, however with lower value, which could suggest that, for instance, the energy could have made a difference in the overall performance.

#### 3

```{r}
run$difference = run$after - run$before
difference_lemo = subset(run,drink=="lemo")$difference
difference_energy = subset(run,drink=="energy")$difference

t.test(difference_lemo, difference_energy)
```
Effectively, even though the hypothesis H0 is not rejected here, the p-value is still low and the means of the differences for lemo and energy shown in the report state that there is a significant difference, specially for the latter one being negative. Thus, the time differences can be considered to be affected by the beverages.

#### 4

One objection would be, since it is expected that the energy drink takes some time to take effect in the pupils' metabolism, the data collected could have also considered that the same amount of beverage can be absorved differently by the pupils and thus, the results might end misleading or even not leading to any conclusion whatsoever.


#### 5

For the same reasons, the metabolism of the pupils react differently. For instance, regardless of what beverage was consumed, a very slim and short person would not present a difference proportional to a chubbier person with more height, under normal circumstances. Thus, the height and the weight of the pupils could have been taken into account.

#### 6

The QQ-plots for the differences are given here after.

```{r}
par(mfrow=c(1,2))
qqnorm(difference_lemo)
qqnorm(difference_energy)
```

### Exercise 3

```{r}
dogs <- read.table("dogs(2).txt", header=TRUE, quote="\"")
```

#### 1 

Please find here after the boxplots and the QQ-plots of the samples, as well as the QQ-plots of the normal distributions with the same sizes of the respective samples.

```{r}
par(mfrow=c(1,3))

boxplot(dogs$isofluorane, xlab="isofluorane")
boxplot(dogs$halothane, xlab="halothane")
boxplot(dogs$cyclopropane, xlab="cyclopropane")

par(mfrow=c(1,2))

# Create QQ-plots of Isofluorane and normal distribution
qqnorm(dogs$isofluorane, xlab="sample", main="QQ-plot Isofluorane")
qqnorm(rnorm(length(dogs$isofluorane)), xlab="random", main="QQ-plot Isofluorane")

# Create QQ-plots of Halothane and normal distribution
qqnorm(dogs$halothane, xlab="sample", main="QQ-plot Halothane")
qqnorm(rnorm(length(dogs$halothane)), xlab="random", main="QQ-plot Halothane")

# Create QQ-plots of Cycloprane and normal distribution
qqnorm(dogs$cyclopropane, xlab="sample", main="QQ-plot Cyclopropane")
qqnorm(rnorm(length(dogs$cyclopropane)), xlab="random", main="QQ-plot Cyclopropane")
```
After analysing the three comparisons between QQ-plots of the drugs and the normal distributions, it is reasonable to state that isufluorane values do not follow a normal distribution, while the other two do. This is explained by the fact that the former one does not really respect a behavior of an uprising line in the QQ-plot graph.

#### 2

Now, we will try to check the hypothesis that is the same under the different drugs.

```{r}
t.test(dogs$isofluorane,dogs$halothane)
t.test(dogs$isofluorane,dogs$cyclopropane)
t.test(dogs$cyclopropane,dogs$halothane)
```
Thus, the results show that the p-value for assuming that the means of concentrations of plasma epinephrine under isofluorane and halothane is 0.7328, which is proof that this hypothesis can not be rejected. For the other two t.tests, the p-values are lower than 0.05, which unables us to accept the hypothesis that the respective pairwise instances in the t.tests have the same mean. So as to better picture this fact, find here after the estimated concentrations of plasma epinephrine for each scenario, which confirms the results so-far obtained:

```{r}
mean_iso=mean(dogs$isofluorane)
mean_halo=mean(dogs$halothane)
mean_cyclo=mean(dogs$cyclopropane)
mean_iso
mean_halo
mean_cyclo
```

#### 3

First, we create data frames as numeric and factor.

```{r}
dogsframeiso = dogs[,-c(2,3)] # subsetting only iso
isofluorane=as.vector(as.matrix(dogs))
group1=as.factor(as.numeric(rep(1:3,each=10)))
dogsframeiso = data.frame(isofluorane, group1)
# dogsframeiso = dogsframeiso[1:10,]

dogsframehalo = dogs[,-c(1,3)] # subsetting only halo 
halothane=as.vector(as.matrix(dogs))
group2=as.factor(as.numeric(rep(1:3,each=10)))
dogsframehalo = data.frame(halothane,group2)
# dogsframehalo = dogsframehalo[12:21,]


dogsframecyclo = dogs[,-c(1,2)] # subsetting only cyclo
cyclopropane=as.vector(as.matrix(dogs))
group3=as.factor(as.numeric(rep(1:3,each=10)))
dogsframecyclo = data.frame(cyclopropane,group3)
# dogsframecyclo = dogsframecyclo[22:30,]

kruskal.test(dogsframeiso,group1)

kruskal.test(halothane,group2)

kruskal.test(cyclopropane,group3)

```
We conclude that the first Kruskal-Wallis test rejects the null hypothesis that the concentration is the same under the different drugs. The two others do not reject this hypothesis. This is different from the previous conclusion because the previous test assumed normality while this test did not.
